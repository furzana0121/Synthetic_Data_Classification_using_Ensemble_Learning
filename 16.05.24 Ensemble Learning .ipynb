{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10ce98c7-5789-4d86-ae00-8564d1dc11db",
   "metadata": {},
   "source": [
    "# Ensemble Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5077cc-4215-4633-8075-701d4110fd2f",
   "metadata": {},
   "source": [
    "# Ensemble Learning is a machine learning technique that involves combining multiple individual models, known as base learners to make predictions or decisions.\n",
    "The main idea behind ensemble learning is that by combining the predictions of multiple models, the overall performance can be improved compared to using a single model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0025e7ab-a17f-4813-b935-c45810d9abde",
   "metadata": {},
   "source": [
    "# (1) Bagging\n",
    "Bagging(Bootstrap Aggregating) is an ensemble learning meethod that combines multiple base learners by training them on different subsets of the training data using bootstrapping. Each base learner is trained independently, and their predictions are combined to make the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "275cec0f-1175-461b-baef-29bcec747060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.865\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Generate a synthetic dataset\n",
    "X,y = make_classification(n_samples=1000, n_features=20, random_state =42)\n",
    "\n",
    "#Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train,y_test = train_test_split(X,y, test_size =0.2, random_state =42)\n",
    "\n",
    "#Initialize  alist to store the base learners\n",
    "base_learners = []\n",
    "\n",
    "#Number of base learners (decision trees)\n",
    "num_base_learners = 10\n",
    "\n",
    "#Train the base learners\n",
    "for i in range(num_base_learners):\n",
    "    #Create a boootstrap sample of the training data\n",
    "    bootstrap_indices = np.random.choice(len(X_train), size = len(X_train), replace =True)\n",
    "    X_bootstrap = X_train[bootstrap_indices]\n",
    "    y_bootstrap = y_train[bootstrap_indices]\n",
    "\n",
    "    #Create and train a base learner (Random Forest)\n",
    "    base_learner = RandomForestClassifier(n_estimators = 10, random_state=42)\n",
    "    base_learner.fit(X_bootstrap, y_bootstrap)\n",
    "\n",
    "    #Add the trained base learner to the list\n",
    "    base_learners.append(base_learner)\n",
    "\n",
    "#Make predictions with each base learner\n",
    "base_predictions =[]\n",
    "for base_learner in base_learners:\n",
    "    y_pred = base_learner.predict(X_test)\n",
    "    base_predictions.append(y_pred)\n",
    "\n",
    "#Combine the predictions using majority voting\n",
    "ensemble_predictions = np.round(np.mean(base_predictions, axis =0))\n",
    "\n",
    "#Calculate the accuracy of the ensemble predictions\n",
    "accuracy = accuracy_score(y_test,ensemble_predictions)\n",
    "print(\"Ensemble Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5367c-b78f-4da2-9725-dc4e99c422d4",
   "metadata": {},
   "source": [
    "# Example 2 MNIST Dataset(handwritten digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f550040-76aa-4a33-99ac-9e5b31b3ab61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\furza\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.9450714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Fetch the MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1, cache = True)\n",
    "\n",
    "#Split the datset into training and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(mnist.data, mnist.target, test_size=0.2, random_state =42)\n",
    "\n",
    "#initialize a base classifier(Decision Tree)\n",
    "base_classifier = DecisionTreeClassifier()\n",
    "\n",
    "#initialize a bagging classifier\n",
    "bagging_classifier=BaggingClassifier(base_classifier, n_estimators =10, random_state = 42)\n",
    "\n",
    "#Train the bagging classifier\n",
    "bagging_classifier.fit(X_train, y_train)\n",
    "\n",
    "#make predictions on the testing set\n",
    "y_pred = bagging_classifier.predict(X_test)\n",
    "\n",
    "#Calculate the accuracy of the bagging classifier\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(\"Bagging Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d03ff9-0c17-409d-bb25-06d9662ca073",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
